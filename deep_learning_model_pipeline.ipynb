{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"2022-01-25\"\n",
    "time = \"11:59:46\"\n",
    "lat, lon = \"1.29531332\", \"103.871146\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Historical data using input date, time, location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_images(date, time, lat, lon):\n",
    "        images = {}\n",
    "        date_obj = datetime.datetime.strptime(date+'T'+time,\"%Y-%m-%dT%H:%M:%S\")\n",
    "        prev_days = [datetime.datetime.strftime(date_obj - datetime.timedelta(days=x),\"%Y-%m-%dT%H:%M:%S\") for x in range(1,8)]\n",
    "        prev_days.append(datetime.datetime.strftime(date_obj - datetime.timedelta(minutes=15),\"%Y-%m-%dT%H:%M:%S\"))\n",
    "        prev_days.append(datetime.datetime.strftime(date_obj - datetime.timedelta(minutes=30),\"%Y-%m-%dT%H:%M:%S\"))\n",
    "        \n",
    "        for prev_day in prev_days:\n",
    "            try:\n",
    "                response = requests.get(f\"https://api.data.gov.sg/v1/transport/traffic-images?date_time={prev_day}\")\n",
    "                response_body = response.json()\n",
    "                items = response_body[\"items\"]\n",
    "                if not (response_body.get(\"items\",[]) and response_body[\"items\"][0].get(\"cameras\",[])):\n",
    "                    print(f\"No data for - {prev_day}\")\n",
    "                    continue\n",
    "                cameras_list = response_body[\"items\"][0][\"cameras\"]\n",
    "                for camera_data in cameras_list:\n",
    "                    location = camera_data[\"location\"]\n",
    "                    if lat == str(location['latitude']) and lon == str(location['longitude']):\n",
    "                        images[prev_day] = camera_data['image']\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"Error while getting data for day - {prev_day} - {str(e)}\")\n",
    "                continue\n",
    "        return images\n",
    "\n",
    "def get_historical_weather_data(date, time, lat, lon):\n",
    "        data = {}\n",
    "        date_obj = datetime.datetime.strptime(date,\"%Y-%m-%d\")\n",
    "        prev_days = [datetime.datetime.strftime(date_obj - datetime.timedelta(x),\"%Y-%m-%d\") for x in range(1,8)]\n",
    "        nearest_station = \"\"\n",
    "        minimum_distance = 180\n",
    "        for prev_day in prev_days:\n",
    "            try:\n",
    "                response = requests.get(f\"https://api.data.gov.sg/v1/environment/rainfall?date_time={prev_day}T{time}\")\n",
    "                response_body = response.json()\n",
    "                items = response_body[\"items\"]\n",
    "                stations = response_body[\"metadata\"][\"stations\"]\n",
    "                if nearest_station == \"\":\n",
    "                    for station in stations:\n",
    "                        tem = abs(float(lat) - station[\"location\"][\"latitude\"]) + abs(float(lon) - station[\"location\"][\"longitude\"])\n",
    "                        if tem < minimum_distance:\n",
    "                            minimum_distance = tem\n",
    "                            nearest_station = station[\"id\"]\n",
    "                    if minimum_distance == 180:\n",
    "                        print(f\"No data for - {prev_day}\")\n",
    "                        continue\n",
    "                for rain_fall in items[0][\"readings\"]:\n",
    "                    if rain_fall[\"station_id\"] == nearest_station:\n",
    "                        data[prev_day]=rain_fall[\"value\"]\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"Error while getting data for day - {prev_day} - {str(e)}\")\n",
    "                continue\n",
    "        return data\n",
    "    \n",
    "# get_historical_weather_data(date, time, lat, lon)\n",
    "# get_historical_images(date, time, lat, lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect number of cars in images - using Cascade RCNN object detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained Model Link:\n",
    "\n",
    "https://drive.google.com/file/d/18E3I8-GeiXXczpwBVRG7vTfVo-pi7aDq/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "\n",
    "def detect_vehicles(model, image_url):\n",
    "    total_vehicles = 0\n",
    "    temp_image_path = \"temp_file.jpg\"\n",
    "    try:\n",
    "        image_response = requests.get(image_url,stream=True)\n",
    "        with open(temp_image_path,'wb') as fh:\n",
    "            image_response.raw.decode_content = True\n",
    "            shutil.copyfileobj(image_response.raw, fh)\n",
    "        result = inference_detector(model, temp_image_path)\n",
    "        os.remove(temp_image_path)\n",
    "        for classes in list(result):\n",
    "            if list(classes):\n",
    "                total_vehicles += len(list(classes))\n",
    "        return total_vehicles\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return -1\n",
    "\n",
    "config_file = 'cnn_model/cascade_rcnn_r50_fpn_20e_coco.py'\n",
    "checkpoint_file = 'cnn_model/cascade_rcnn_r50_fpn_20e_coco.pth'\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "images = get_historical_images(date, time, lat, lon)\n",
    "vehicles_count = [detect_vehicles(model,images[x]) for x in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunRNN Model to predict car count from last 7 days data (car count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_model.lstm_model import LSTM\n",
    "\n",
    "model = LSTM(input_dim=1,hidden_dim=4,num_layers=32,output_dim=1)\n",
    "model.load_state_dict(torch.load('rnn_model/rnn_model.pth'))\n",
    "model.eval()\n",
    "inputs = np.asarray([vehicles_count],dtype=np.float32)\n",
    "inputs = np.expand_dims(inputs,2)\n",
    "car_prediction = model(torch.from_numpy(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(car_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
